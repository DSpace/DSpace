# DRUM Logging

## Introduction

This document describes DRUM customizations to the DSpace logging configuration.

DRUM customizes DSpace to enable JSON-formatted log entries when using
Kubernetes, as it enables more flexible search options when using Splunk.

By default, DSpace configures the Spring Boot embedded Tomcat server to use the
Log4j2 logging framework, via the
"org.springframework.boot:spring-boot-starter-log4j2" Maven dependency, in
preference to the stock Spring Boot "logback" framework.

## Handling Multiple Log Files

DRUM generates multiple log files:

* dspace.log - the DSpace application log. Also generated by the "cron" process
* dspace-cli.log - the DSpace command-line application log. Added in DSpace 8.1
* checker.log - Log from the "dspace checker" command
* Tomcat access log - Apache-style access log
* etdloader.log - UMD custom ETD log, which requires special handling
  (see below)

Having multiple logs is problematic for Kubernetes, because if the logs are
simply dumped to the console, the various logs get intermixed together.

Having the log entries output as JSON enables the logs to be untangled by adding
a "logFile" attribute. This attribute references the name of the log file the
log entry is directed to, for example, `logFile:dspace.log`. This makes is
possible to dump all the logs to the console, while still being able to search
a particular log file's entries via Splunk.

### Log4j

For the logs using Log4j, the process of adding the "logFile" attribute is
straightforward -- a "EventTemplateAdditionalField" is added to the stock Log4j
"JsonTemplateLayout" stanza used to output the log in JSON format. The
following example adds a "logFile:dspace.log" JSON attribute:

```xml
<JsonTemplateLayout eventTemplateUri="classpath:EcsLayout.json">
    <EventTemplateAdditionalField key="logfile" value="dspace.log"/>
</JsonTemplateLayout>
```

### Embedded Tomcat access log

The format of the embedded Tomcat access log is controlled by an
"Access Log Valve"
(see <https://tomcat.apache.org/tomcat-10.0-doc/config/valve.html#Access_Logging>).

JSON-formatted logs can be output using the stock "JsonAccessLogValve", but this
valve *does not* allow for the addition of a "logFile" attribute. To support
the "logFile" attribute, a UMD custom subclass,
"dspace/modules/server-boot/src/main/java/org/dspace/app/UmdExtendedJsonAccessLogValve.java"
has been created which enables a single JSON attribute to be defined and
appended to the JSON log output.

To enable JSON-formatted logging, the embedded Tomcat server provided by Spring
Boot must be modified to use a "UmdExtendedJsonAccessLogValve"
valve instead of the default "AccessLogValve". This is done via a custom
"WebServerFactoryCustomizer" in the
"dspace/modules/server-boot/src/main/java/org/dspace/app/UmdTomcatWebServerFactoryCustomizer.java"
class.

The "dspace/modules/server-boot/src/main/java/org/dspace/app/ServerBootApplication.java"
class has been customized to include the "UmdTomcatWebServerFactoryCustomizer"
class has part of its configuration.

JSON logging is enabled by setting the
"umd.server.tomcat.accesslog.json.enabled" property to "true". The
stock "server.tomcat.accesslog.enabled" should be set to "false"
to prevent double-logging from the stock Spring Boot AccessLogValve.

The appended JSON attribute is added to the stock JsonAccessLogValve patten
using an attribute formatted as "#\<KEY>:\<VALUE>#". The
following example adds a "logFile:dspace.log" JSON attribute:

```text
server.tomcat.accesslog.pattern=%h %l %u %t "%r" %s %b %D #logFile:dspace.log#
```

### ETD logging, etdloader.log, and UMD_DSPACE_CLI_LOG_CONFIG

There are four scripts involved in ETD uploads

* load-etd - A UMD custom Perl script that actually processes the ETD uploads
  via the stock "dspace" script and the "edu.umd.lib.dspace.app.EtdLoader"
  class.
* dspace - the stock script provided by DSpace for running command-line tasks
* load-etd-nightly - A UMD custom Perl script that is run by cron to determine
  if there are any ETD uploads to process via the "load-etd" script
* script-mail-wrapper - A UMD custom shell script that wraps another script
  and sends the console output to a specified email address.

For cron-based ETD uploads, there are two artifacts that are be produced:

* An email containing the console output of the "load-etd-nightly" script
* A more detailed log of the output from the "load-etd-nightly" script

The introduction of the "dspace-cli.log" as the default log for the "dspace"
script in DSpace 8.1 interfered with both the email and log needed for the
ETD functionality.

To restore the expected ETD email and log, the "dspace" script was customized
with a "UMD_DSPACE_CLI_LOG_CONFIG" environment variable to override the
default "log4j2-cli.xml" Log4j2 configuration file with a different
configuration file, if specified.

This allows the "load-etd" script to use the "log4j2-etdloader.xml"
configuration file in place of the "log4j2-cli.xml".

In keeping with the pre-DSpace 8.1 behavior:

* When run manually, the "load-etd" script creates a "etdloader.log" in the
  DSpace log directory.
* When run using the "script-mail-wrapper" script,
  "script-mail-wrapper-\<SCRIPT>-\<DATE>.log" file is created where \<SCRIPT> is
  the name of the wrapped script, and \<DATE> is a timestamp.

One change that could not be preserved in the DSpace 8.1 upgrade is that the
log file (either "etdloader.log" or "script-mail-wrapper-*.log") does not
contain the detailed DEBUG information as it did previously. This was an
intentional decision because there was a conflict between:

1) Having the email be similar to the email sent when running in Kubernetes

and

2) Having a text-based log (as opposed to JSON-formatted) in the local
   development environment.

In Kubernetes, the logging is significantly different, in that the
"log4j2-etdloader.xml" is replaced, and uses JSON-formatted logging for
compatibility with Splunk. This enables the DEBUG logs to be stripped from the
email, while preserving them in the log sent to Splunk.

In the local development environment, since a text-based log was preferred,
being easier to read, it is not possible to do the same level of filtering.

## Local Development Environment Logging

In the local development environment, DSpace is run via Docker Compose, and
the DSpace application logs are controlled by the
"dspace/config/log4j2-container.xml" file.

The Tomcat server access logs are controlled by Spring Boot. The default
Spring Boot configuration, which does not enable the Tomcat server access log,
is typically used, but can be managed by Spring Boot "server.tomcat.accesslog.*"
properties in the "dspace/config/local.cfg", see
<https://docs.spring.io/spring-boot/docs/3.2.6/reference/html/application-properties.html#appendix.application-properties.server>.

To enable JSON-formatted logging (similar to how logs are displayed in
Kubernetes), do the following:

1) In "dspace/config/log4j2-container.xml", replace the "PatternLayout"
   stanza in the "A1" appender:

    ```xml
            <Appender name='A1'
                      type='Console'
                <JsonTemplateLayout eventTemplateUri="classpath:EcsLayout.json">
                    <EventTemplateAdditionalField key="logfile" value="dspace.log"/>
                </JsonTemplateLayout>
           </Appender>
    ```

   This will enable JSON-formatted logging for the DSpace application logs.

2) Add the following to "dspace/config/local.cfg" to enable the Tomcat access
   logs (in JSON format):

   ```text
   # Tomcat access log
   # Disable stock AccessLogValve
   server.tomcat.accesslog.enabled=false
   # Set umd.server.tomcat.accesslog.json.enabled to "true" for JSON logging
   umd.server.tomcat.accesslog.json.enabled=true
   server.tomcat.accesslog.directory=/dev
   server.tomcat.accesslog.prefix=stdout
   server.tomcat.accesslog.buffered=false
   server.tomcat.accesslog.suffix=
   server.tomcat.accesslog.file-date-format=
   server.tomcat.accesslog.pattern=%h %l %u %t "%r" %s %b %D #logFile:access.log#
   ```

## Kubernetes JSON-formatted Logging

### DRUM - DSpace Logs

In Kubernetes, the DSpace application logs are controlled by the
"overlays/\<NAMESPACE>/log4j2.xml" file (where "\<NAMESPACE>" is the Kubernetes
namespace (i.e., "sandbox", "test", "qa", or "prod")).

To enable JSON-formatted logging, the Log4j "Appenders" are modified to use
the "JsonTemplateLayout", i.e.:

```xml
        <Appender name='A1'
                  ...
        >
            ...
            <JsonTemplateLayout eventTemplateUri="classpath:EcsLayout.json">
                <EventTemplateAdditionalField key="logfile" value="dspace.log"/>
            </JsonTemplateLayout>
            ...
        </Appender>
```

The JSON-formatted Tomcat access log is enabled by the
"umd.server.tomcat.accesslog.json.enabled" property in the
"overlays/\<NAMESPACE>/local.cfg" file:

```text
# Disable stock AccessLogValve
server.tomcat.accesslog.enabled=false
# Set umd.server.tomcat.accesslog.json.enabled to "true" for JSON logging
umd.server.tomcat.accesslog.json.enabled=true
server.tomcat.accesslog.directory=/dev
server.tomcat.accesslog.prefix=stdout
server.tomcat.accesslog.buffered=false
server.tomcat.accesslog.suffix=
server.tomcat.accesslog.file-date-format=
server.tomcat.accesslog.pattern=%h %l %u %t "%r" %s %b %D #logFile:access.log#
```

### DRUM - Solr Logs

#### Solr Log4j application logs

In Kubernetes, the Solr application logs are controlled by the
"overlays/\<NAMESPACE>/solr/log4j2.xml" file (where "\<NAMESPACE>" is the
Kubernetes namespace (i.e., "sandbox", "test", "qa", or "prod").

The "log4j2.xml" file configures Log4j to use the "JsonTemplateLayout", to
provide JSON-formatted output to Splunk.

#### Solr Java garbage collection logs

The command-line options provided to the JVM to run Solr are configured by the
stock "solr" Docker image to log Java garbage collection activity in the
"/var/solr/logs/solr_gc.log" file. This logging is *not* controlled by Log4j,
and is *not* JSON-formatted.

The command-line options that generate the "solr_gc.log" specify a rolling log
with each file limited to 20 megabytes, and a maximum of 10 files, so the
maximum size of the logs should be 200 megabytes.

The Solr garbage collection logs are *not* sent to Splunk, because as it does
not seem particularly useful.

## log4j-layout-template-json Dependency

The "JsonTemplateLayout" used in the Log4j appender is provided by the
"org.apache.logging.log4j:log4j-layout-template-json" Maven dependency.

In order for the "JsonTemplateLayout" class to be available to both the
Spring Boot embedded Tomcat server, and the DSpace Java application, the
"log4j-layout-template-json" dependency has been added to the
"dspace-api/pom.xml" file, as this gives it the earliest integration at
startup.

If JSON formatting is only needed for the embedded Tomcat server, and *not*
the DSpace application, the "log4j-layout-template-json" only needs to be added
to the "dspace/modules/server-boot/pom.xml" file.
