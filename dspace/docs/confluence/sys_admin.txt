h1. DSpace System Documentation: System AdministrationDSpace operates on several levels: as a Tomcat servlet, cron jobs, and on-demand operations. This section explains many of the on-demand operations. Some of the command operations may be also set up as cron jobs. Many of these operations are performed at the Command Line Interface (CLI) also known as the Unix prompt ($:) Future reference will use the term CLI when the use needs to be at the command line.Below is the "Command Help Table". This table explains what data is contained in the individual command/help tables in the sections that follow.|Command used: |_The directory and where the command is to be found._||Java class: |_The actual java program doing the work._||Arguments: |_The required/mandatory or optional arguments available to the user._|*DSpace Command Launcher*. With DSpace Release 1.6, the many commands and scripts have been replaced with a simple _\[dspace\]/bin/dspace <command>_ command. See Application Layer chapter for the details of the DSpace Command Launcher.h2. Community and Collection Structure ImporterThis CLI tool gives you the ability to import acommunity and collection structure directory froma source XML file.|Command used: |_\[dspace\]/bin/dspace structure-builder_||Java class: |_org.dspace.administer.StructBuilder_||Argument: short and long (if available) forms: |Description of the argument ||_-f_|Source xml file.  ||_-o_|Output xml file. ||_-e_|Email of DSpace Administrator. |The administrator need to build the source xml document in the following format:{code}<import_structure>
        <community>
                <name>Community Name</name>
                <description>Descriptive text</description>
                <intro>Introductory text</intro>
                <copyright>Special copyright notice</copyright>
                <sidebar>Sidebar text</sidebar>
                    <community>
                		<name>Sub Community Name</name>
                		<community> ...[ad infinitum]... 
                		</community>
                	</community>
                			<collection>
                        		<name>Collection Name</name>
                        		<description>Descriptive text</description>
                        		<intro>Introductory text</intro>
                        		<copyright>Special copyright notice</copyright>
                        		<sidebar>Sidebar text</sidebar>
                        		<license>Special licence</license>
                        		<provenance>Provenance information</provenance>
                			</collection>
         </community>
</import_structure>
{code}The resulting output document will be as follows:{code}<import_structure>
     <community identifier="123456789/1">
                <name>Community Name</name>
                <description>Descriptive text</description>
                <intro>Introductory text</intro>
                <copyright>Special copyright notice</copyright>
                <sidebar>Sidebar text</sidebar>
                <community identifier="123456789/2">
                        <name>Sub Community Name</name>
                        <community identifier="123456789/3"> ...[ad infinitum]... 
                        </community>
                </community>
                    <collection identifier="123456789/4">
                        <name>Collection Name</name>
                        <description>Descriptive text</description>
                        <intro>Introductory text</intro>
                        <copyright>Special copyright notice</copyright>
                        <sidebar>Sidebar text</sidebar>
                        <license>Special licence</license>
                        <provenance>Provenance information</provenance>
                   </collection>
        </community>
</import_structure>
{code}This command-line tool gives you the ability to import a community and collection structure directly from a source XML file. It is executed as follows:_\[dspace\]/bin/dspace structure-builder -f /path/to/source.xml -o path/to/output.xml -e admin@user.com_This will examine the contents of _\[source xml\]_, import the structure into DSpace while logged in as the supplied administrator, and then output the same structure to the output file, but including the handle for each imported community and collection as an attribute.h3. Limitation*  Currently this does not export community and collection structures, although it should only be a small modification to make it do so h2. Package Importer and ExporterThis command-line tool gives you access to the Packager plugins. It can _ingest_ a package to create a new DSpace Item, or _disseminate_ an Item as a package.To see all the options, invoke it as:__\[dspace\]___/bin/packager --help_ This mode also displays a list of the names of package ingesters and disseminators that are available.h3. IngestingTo ingest a package from a file, give the command:{code}[dspace]/bin/packager -e  user -c  handle -t  packagerpath{code} Where __user__ is the e-mail address of the E-Person under whose authority this runs; __handle__ is the Handle of the collection into which the Item is added, __packager__ is the plugin name of the package ingester to use, and __path__ is the path to the file to ingest (or _"-"_ to read from the standard input). Here is an example that loads a PDF file with internal metadata as a package:_/dspace/bin/packager -e florey@mit.edu -c 1721.2/13 -t pdf thesis.pdf_This example takes the result of retrieving a URL and ingests it:{code}wget -O - http://alum.mit.edu/jarandom/my-thesis.pdf | \
/dspace/bin/packager -e florey@mit.edu -c 1721.2/13  -t pdf -{code}h3. DisseminatingTo disseminate an Item as a package, give the command:{code}[dspace]/bin/packager -e  user -d -i  handle -t packager path{code}Where __user__ is the e-mail address of the E-Person under whose authority this runs; __handle__ is the Handle of the Item to disseminate; __packager__ is the plugin name of the package disseminator to use; and __path__ is the path to the file to create (or _"-"_ to write to the standard output). This example writes an Item out as a METS package in the file "454.zip":_/dspace/bin/packager -e florey@mit.edu -d -i 1721.2/454 -t METS 454.zip_h3. METS packagesSince DSpace 1.4 release, the software includes a package disseminator and matching ingester for the DSpace METS SIP (Submission Information Package) format. They were created to help end users prepare sets of digital resources and metadata for submission to the archive using well-defined standards such as [METS|http://www.loc.gov/standards/mets/|METS], [MODS|http://www.loc.gov/standards/mods/|MODS], and [PREMIS|http://www.loc.gov/standards/premis/|PREMIS]. The plugin name is _METS_ by default, and it uses MODS for descriptive metadata.The DSpace METS SIP profile is available at: [http://www.dspace.org/standards/METS/SIP/profilev1p0/metsipv1p0.pdf|http://www.dspace.org/standards/METS/SIP/profilev1p0/metsipv1p0.pdf|http://www.dspace.org/standards/METS/SIP/profilev1p0/metsipv1p0.pdf] .h2. Item Importer and ExporterDSpace has a set of command line tools for importing and exporting items in batches, using the DSpace simple archive format. The tools are not terribly robust, but are useful and are easily modified. They also give a good demonstration of how to implement your own item importer if desired.h3. DSpace Simple Archive FormatThe basic concept behind the DSpace's simple archive format is to create an archive, which is directory full of items, with a subdirectory per item. Each item directory contains a file for the item's descriptive metadata, and the files that make up the item.{code}
archive_directory/
    item_000/
        dublin_core.xml         -- qualified Dublin Core metadata for metadata fields belonging to the dc schema
        metadata_[prefix].xml   -- metadata in another schema, the prefix is the name of the schema as registered with the metadata registry 
        contents                -- text file containing one line per filename
        file_1.doc              -- files to be added as bitstreams to the item
        file_2.pdf
    item_001/
        dublin_core.xml
        contents
        file_1.png
        ...
{code}The _dublin_core.xml_ or _metadata_\[prefix\].xml_file has the following format, where each metadata element has it's own entry within a _<dcvalue>_ tagset. There are currently three tag attributes available in the _<dcvalue>_ tagset:* _<element>_ - the Dublin Core element* _<qualifier>_ - the element's qualifier* _<language>_ - (optional)ISO language code for element{code}
<dublin_core>
    <dcvalue element="title" qualifier="none">A Tale of Two Cities</dcvalue>
    <dcvalue element="date" qualifier="issued">1990</dcvalue>
    <dcvalue element="title" qualifier="alternate" language="fr">J'aime les Printemps</dcvalue>
</dublin_core>

{code}(Note the optional language tag attribute which notifies the system that the optional title is in French.)Every metadata field used, must be registered via the metadata registry of the DSpace instance first.The _contents_ file simply enumerates, one file per line, the bitstream file names. See the following example:{code}
        file_1.doc
        file_2.pdf
        license
{code} Please notice that the _license_ is optional, and if you wish to have one included, you can place the file in the .../item_001/ directory, for example.The bitstream name may optionally be followed by the sequence:_\tbundle:bundlename_ where '\t' is the tab character and 'bundlename' is replaced by the name of the bundle to which the bitstream should be added. If no bundle is specified, the bitstream will be added to the 'ORIGINAL' bundle.h3. Importing ItemsBefore running the item importer over items previously exported from a DSpace instance, please first refer to Transferring Items Between DSpace Instances.|Command used: |__\[dspace\]___/bin/dspace import_||Java class: |_org.dspace.app.itemimport.ItemImport_||Arguments short and (long) forms: |Description ||_-a_ or _--add_|Add items to DSpace ‡ ||_-r_ or _--replace_|Replace items listed in mapfile ‡ ||_-d_ or _--delete_|Delete items listed in mapfile ‡ ||_-s_ or _--source_|Source of the items (directory) ||_-c_ or _--collection_|Destination Collection by their Handle or database ID ||_-m_ or _--mapfile_|Where the mapfile for items can be found (name and directory) ||_-e_ or _--eperson_|Email of eperson doing the importing ||_-w_ or _--workflow_|Send submission through collection' workflow ||_-n_ or _--notify_|Kicks off the email alerting of the item(s) has(have) been imported ||_-t_ or _--test_|Test run—do not actually import items ||_-p_ or _--template_|Apply the collection template ||_-R_ or _--resume_|Resume a failed import (Used on Add only) ||_-h_ or _--help_|Command help |‡ These are mutually exclusive.The item importer is able to batch import unlimited numbers of items for a particular collection using a very simple CLI command and 'arguments'
			h4. Adding Items to a CollectionTo add items to a collection, you gather the following information:* eperson * Collection ID (either Handle (e.g. 123456789/14) or Database ID (e.g. 2) * Source directory where the items reside * Mapfile. Since you don't have one, you need to determine where it will be (e.g. /Import/Col_14/mapfile) At the command line:_\[dspace\]/bin/import --add --eperson=joe@user.com --collection=CollectionID --source=items_dir --mapfile=mapfile_or by using the short form:_\[dspace\]/bin/import -a -e joe@user.com -c CollectionID -s items_dir -m mapfile_The above command would cycle through the archive directory's items, import them, and then generate a map file which stores the mapping of item directories to item handles. *SAVE THIS MAP FILE.* Using the map file you can use it for replacing or deleting (unimporting) the file. *Testing.* You can add _--test_ (or _-t_) to the command to simulate the entire import process without actually doing the import. This is extremely useful for verifying your import files before doing the actual import.h4. Replacing Items in CollectionReplacing existing items is relatively easy. Remember that mapfile you were _supposed_ to save? Now you will use it. The command (in short form):_\[dspace\]/bin/import -r -e joe@user.com -c collectionID -s items_dir -m mapfile_Long form:_\[dspace\]/bin/import --replace --eperson=joe@user.com --collection=collectionID --source=items_dire --mapfile=mapfile_h4. Deleting or Unimporting Items in a CollectionYou are able to unimport or delete items provided you have the mapfile. Remember that mapfile you were _supposed_ to save? The command is (in short form):_\[dspace\]/bin/import -d -m mapfile_In long form:_\[dspace/bin/import --delete --mapfile mapfile_. Other Options*Workflow*. The importer usually bypasses any workflow assigned to a collection. But add the _--workflow _(_-w_) argument will route the imported items through the workflow system.*Templates*. If you have templates that have constant data and you wish to apply that data during batch importing, add the _--template _(_-p_) argument.*Resume*. If, during importing, you have an error and the import is aborted, you can use the _--resume _(_-R_) flag that you can try to resume the import where you left off after you fix the error.h3. Exporting ItemsThe item exporter can export a single item or a collection of items, and creates a DSpace simple archive for each item to be exported.|Command used: |__\[dspace\]___/bin/dspace export_||Java class: |_org.dspace.app.itemexport.ItemExport_||Arguments short and (long) forms: |Description ||_-t_ or _--type_|Type of export. _COLLECTION_ will inform the program you want the whole collection. _ITEM_ will be only the specific item. (You will actually key in the keywords in all caps. See examples below.)||_-i_ or _--ed_|The ID or Handle of the Collection or Item to export. ||_-d_ or _--dest_|The destination of where you want the file of items to be placed. You place the path if necessary.  ||_-n_ or _--number_|Sequence number to begin export the items with. Whatever number you give, this will be the name of the first directory created for your export. The layout of the export is the same as you would set your layout for an Import. ||_-m_ or _--migrate_|Export the item/collection for migration. This will remove the handle and metadata that will be re-created in the new instance of DSpace. ||_-h_ or _--help_|Brief Help. |*Exporting a Collection*To export a collection's items you type at the CLI:\[dspace\]/bin/dspace export --type=COLLECTION --id=collID --dest=dest_dir --number=seq_numShort form:_\[dspace\]/bin/dspace export -t COLLECTION -d CollID or Handle -d /path/to/destination -n Some_number_*Exporting a Single Item*The keyword _COLLECTION_ means that you intend to export an entire collection. The ID can either be the database ID or the handle. The exporter will begin numbering the simple archives with the sequence number that you supply. To export a single item use the keyword _ITEM_ and give the item ID as an argument:_\[dspace\]/bin/dspace export --type=ITEM --id=itemID --dest=dest_dir --number=seq_num_Short form:_\[dspace\]/bin/dspace export -t ITEM -i itemID or Handle -d /path/to/destination -n some_unumber_Each exported item will have an additional file in its directory, named 'handle'. This will contain the handle that was assigned to the item, and this file will be read by the importer so that items exported and then imported to another machine will retain the item's original handle.*The _-m_ Arugment*Using the _-m_ argument will export the item/collection and also perform the migration step. It will perform the same process that the next section Transferring Items Between DSpace Instances  performs. We recommend that the next section be read in conjunction with this flag being used. h2. Transferring Items Between DSpace InstancesMigration of DataWhere items are to be moved between DSpace instances (for example from a test DSpace into a production DSpace) the item exporter and item importer can be used in conjunction with a script to assist in this process.After running the item exporter each _dublin_core.xml_ file will contain metadata that was automatically added by DSpace. These fields are as follows:* date.accessioned * date.available * date.issued * description.provenance * format.extent * format.mimetype * identifier.uri In order to avoid duplication of this metadata, run_dspace_migrate </path/to/exported item directory>_prior to running the item importer. This will remove the above metadata items, except for date.issued - if the item has been published or publicly distributed before and _identifier.uri_ - if it is not the handle, from the _dublin_core.xml_ file and remove all _handle_ files. It will then be safe to run the item exporter.h2. Item UpdateItemUpdate is a batch-mode command-line tool for altering the metadata and bitstream content of existing items in a DSpace instance. It is a companion tool to ItemImport and uses the DSpace simple archive format to specify changes in metadata and bitstream contents. Those familiar with generating the source trees for ItemImporter will find a similar environment in the use of this batch processing tool.For metadata, ItemUpdate can perform 'add' and 'delete' actions on specified metadta elements. For bitstreams, 'add' and 'delete' are similarly available. All these actions can be combined in a single batch run.ItemUpdate supports an undo feature for all actions except bitstream deletion. There is also a test mode, as with ItemImport. However, unlike ItemImport, there is no resume feature for incomplete processing. There is more extensive logging with a summary statement at the end with counts of successful and unsuccessful items processed.One probable scenario for using this tool is where there is an external primary data source for which the DSpace instance is a secondary or down-stream system. Metadata and/or bitstream content changes in the primary system can be exported to the simple archive format to be used by ItemUpdate to synchronize the changes.A note on terminology: *item* refers to a DSpace item. *metadata element* refers generally to a qualified or unqualified element in a schema in the form _\[schema\].\[element\].\[qualifier\]_ or _\[schema\].\[element\]_ and occasionally in a more specific way to the second part of that form. *metadata field* refers to a specific instance pairing a metadata element to a value.h3. DSpace simple Archive FormatAs with ItemImporter, the idea behind the DSpace's simple archive format is to create an archive directory with a subdirectory per item. There are a few additional features added to this format specifically for ItemUpdate. Note that in the simple archive format, the item directories are merely local references and only used by ItemUpdate in the log output.The user is referred to the previous section DSpace Simple Archive Format.Additionally, the use of a *delete_contents* is now available. This file lists the bitstreams to be deleted, one bitstream ID per line. Currently, no other identifiers for bitstreams are usable for this function. This file is an addition to the Archive format specifically for ItemUpdate.The optional suppress_undo file is a flag to indicate that the 'undo archive' should not be written to disk. This file is usually written by the application in an undo archive to prevent a recursive undo. This file is an addition to the Archive format specifically for ItemUpdate.h3. ItemUpdate Commands|Command used: |__\[dspace\]___/bin/dspace itemupdate_||Java class: |_org.dspace.app.itemimport.ItemUpdate_||Arguments short and (long) forms: |Description ||_-a_ or _--addmetadata \[metadata element\]_|Repeatable for multiple elements. The metadata element should be in the form dc.x or dc.x.y. The mandatory argument indicates the metadata fields in the dublin_core.xml file to be added unless already present. However, duplicate fields will not be added to the item metadata without warning or error. ||_-d_ or _--deletemetadata \[metadata element\]_|Repeatable for multiple elements. All metadata fields matching the element will be deleted. ||_-A_ or _--addbitstream_|Adds bitstreams listed in the contents file with the bistream metadata cited there. ||_-D_ or _--deletebitstream \[filter plug classname or alis\]_|Not repeatable. With no argument, this operation deletes bistreams listed in the _deletes_contents_ file. Only bitstream ids are recognized identifiers for this operatiotn. The optional filter argument is the classname of an implementation of _org.dspace.app.itemdupate.BitstreamFilter_ class to identify files for deletion or one of the aliases (ORIGINAL, ORIGINAL_AND_DERIVATIVES, TEXT, THUMBNAIL) which reference existing filters based on membership in a bundle of that name. IN this case, the _delete_contents_ file is not required for any item. The filter properties file will contains properties pertinent to the particular filer used. Multiple filters are not allowed.||_-h_ or _--help_|Displays brief command line help. ||_-e_ or _--eperson_|Email address of the person or the user's database ID *(Required)*||_-s_ or _--source_|Directory archive to process *(Required)*||_-i_ or _--itemidentifier_|Specifies an alternate metadata field (not a handle) used to hold an identifier used to match the DSpace item with that in the archive. If omitted, the item handle is expected to be located in the _dc.identifier.uri_ field. (Optional)||_-t_ or _--test_|Runs the process in test mode with logging but no changes applied to the DSpace instance. (Optional) ||_-P_ or _--alterprovenance_|Prevents any changes to the provenance field to represent changes in the bitstream content resulting from an Add or Delete. No provenance statements are written for thumbnails or text derivative bitstreams, un keepin with the practice of MediaFilterManager. (Optional) ||_-F_ or _--filterproperties_|The filter properties files to be used by the delete bitstreams action (Optional) |. CLI Examples*Adding Metadata*:_\[dspace\]/bin/dspace updateitem -e joe@user.com -s \[path/to/archive\] -a dc.description__This will add from your archive the dc element description based on the handle from the URI (since the -i argument wasn't used)._h2. Registering (Not Importing) BitstreamsRegistration is an alternate means of incorporating items, their metadata, and their bitstreams into DSpace by taking advantage of the bitstreams already being in storage accessible to DSpace. An example might be that there is a repository for existing digital assets. Rather than using the normal interactive ingest process or the batch import to furnish DSpace the metadata and to upload bitstreams, registration provides DSpace the metadata and the location of the bitstreams. DSpace uses a variation of the import tool to accomplish registration.h3. Accessible StorageTo register an item its bitstreams must reside on storage accessible to DSpace and therefore referenced by an asset store number in _dspace.cfg_. The configuration file _dspace.cfg_ establishes one or more asset stores through the use of an integer asset store number. This number relates to a directory in the DSpace host's file system or a set of SRB account parameters. This asset store number is described in The _dspace.cfg_ Configuration Properties File section and in the _dspace.cfg_ file itself. The asset store number(s) used for registered items should generally not be the value of the _assetstore.incoming_ property since it is unlikely that you will want to mix the bitstreams of normally ingested and imported items and registered items.h3. Registering Items Using the Item ImporterDSpace uses the same import tool that is used for batch import except that several variations are employed to support registration. The discussion that follows assumes familiarity with the import tool.The archive format for registration does not include the actual content files (bitstreams) being registered. The format is however a directory full of items to be registered, with a subdirectory per item. Each item directory contains a file for the item's descriptive metadata (_dublin_core.xml_) and a file listing the item's content files (_contents_), but not the actual content files themselves.The _dublin_core.xml_ file for item registration is exactly the same as for regular item import.The _contents_ file, like that for regular item import, lists the item's content files, one content file per line, but each line has the one of the following formats:{code}-r -s n -f filepath
-r -s n -f filepath\tbundle:bundlename
-r -s n -f filepath\tbundle:bundlename\tpermissions: -[r|w] 'group name'
-r -s n -f filepath\tbundle:bundlename\tpermissions: -[r|w] 'group	name'\tdescription: some text{code}where* _-r_ indicates this is a file to be registered* _-s n_ indicates the asset store number (_n_)* _-f filepath_ indicates the path and name of the content file to be registered (filepath)* _\t_ is a tab character* _bundle:bundlename_ is an optional bundle name* _permissions: -\[r|w\] 'group name'_ is an optional read or write permission that can be attached to the bitstream* _description: some text_ is an optional description field to add to the fileThe bundle, that is everything after the filepath, is optional and is normally not used.The command line for registration is just like the one for regular import:_\[dspace\]/bin/dspace import -a -e joe@user.com -c collectionID -s items_dir -m mapfile_(or by using the long form)_\[dspace\]/bin/dspace import --add -eperson=joe@user.com --collection=collectionID --source=items_dir --map=mapfile_The _--workflow_ and _--test_ flags will function as described in Importing Items.The _--delete_ flag will function as described in Importing Items but the registered content files will not be removed from storage. See Deleting Registered Items.The _--replace_ flag will function as described in Importing Items but care should be taken to consider different cases and implications. With old items and new items being registered or ingested normally, there are four combinations or cases to consider. Foremost, an old registered item deleted from DSpace using _--replace_ will not be removed from the storage. See Deleting Registered Items. where is resides. A new item added to DSpace using _--replace_ will be ingested normally or will be registered depending on whether or not it is marked in the _contents_ files with the -r.h3. Internal Identification and Retrieval of Registered ItemsOnce an item has been registered, superficially it is indistinguishable from items ingested interactively or by batch import. But internally there are some differences:First, the randomly generated internal ID is not used because DSpace does not control the file path and name of the bitstream. Instead, the file path and name are that specified in the _contents_ file.Second, the _store_number_ column of the bitstream database row contains the asset store number specified in the _contents_ file.Third, the _internal_id_ column of the bitstream database row contains a leading flag (_-R_) followed by the registered file path and name. For example, _-Rfilepath_ where _filepath_ is the file path and name relative to the asset store corresponding to the asset store number. The asset store could be traditional storage in the DSpace server's file system or an SRB account.Fourth, an MD5 checksum is calculated by reading the registered file if it is in local storage. If the registerd file is in remote storage (say, SRB) a checksum is calculated on just the file name! This is an efficiency choice since registering a large number of large files that are in SRB would consume substantial network resources and time. A future option could be to have an SRB proxy process calculate MD5s and store them in SRB's metadata catalog (MCAT) for rapid retrieval. SRB offers such an option but it's not yet in production release.Registered items and their bitstreams can be retrieved transparently just like normally ingested items.h3. Exporting Registered ItemsRegistered items may be exported as described in Exporting Items. If so, the export directory will contain actual copies of the files being exported but the lines in the contents file will flag the files as registered. This means that if DSpace items are "round tripped" (see Transferring Items Between DSpace Instances) using the exporter and importer, the registered files in the export directory will again registered in DSpace instead of being uploaded and ingested normally.h3. METS Export of Registered ItemsThe METS Export Tool can also be used but note the cautions described in that section and note that MD5 values for items in remote storage are actually MD5 values on just the file name.h3. Deleting Registered ItemsIf a registered item is deleted from DSpace, either interactively or by using the _--delete_ or _--replace_ flags described in Importing Items, the item will disappear from DSpace but it's registered content files will remain in place just as they were prior to registration. Bitstreams not registered but added by DSpace as part of registration, such as _license.txt_ files, will be deleted.h2. METS ToolsThe experimental (incomplete) METS export tool writes DSpace items to a filesystem with the metadata held in a more standard format based on METS.h3. The Export ToolThis tool is obsolete, and does not export a complete AIP. It's use is strongly deprecated.|Command used: |__\[dspace\]___/bin/dspace mets-export_||Java class: |_org.dspace.app.mets.METSExport_||Arguments short and (long) forms: |Description ||_-a_ or _--all_|Export all items in the archive. ||_-c_ or _--collection_|Handle of the collection to export. ||_-d_ or _--destination_|Destination directory. ||_-i_ or _--item_|Handle of the item to export. ||_-h_ or _--help_|Help |The following are examples of the types of process the METS tool can provide.*Exporting an individual item.* From the CLI:__\[dspace\]___/bin/dspace mets-export -i ___\[handle\] -d /path/to/destination__*Exporting a collection*. From the CLI:_\[dspace\]/bin/dspace mets-export -c \[handle\] -d /path/to/destination_*Exporting all the items in DSpace.* From the CLI:_\[dspace\]/bin/dspace mets-export -a -d /path/to/destination_h3. The AIP FormatNote that this tool is deprecated, and the output format is not a true AIPEach exported item is written to a separate directory, created under the base directory specified in the command-line arguments, or in the current directory if _--destination_ is omitted. The name of each directory is the Handle, URL-encoded so that the directory name is 'legal'.Within each item directory is a _mets.xml_ file which contains the METS-encoded metadata for the item. Bitstreams in the item are also stored in the directory. Their filenames are their MD5 checksums, firstly for easy integrity checking, and also to avoid any problems with 'special characters' in the filenames that were legal on the original filing system they came from but are illegal in the server filing system. The _mets.xml_ file includes XLink pointers to these bitstream files.An example AIP might look like this:* _hdl%3A123456789%2F8/_** _mets.xml_ -- METS metadata** _184BE84F293342_ -- bitstream** _3F9AD0389CB821_** _135FB82113C32D_The contents of the METS in the _mets.xml_ file are as follows:*  A _dmdSec_ (descriptive metadata section) containing the item's metadata in [Metadata Object Description Schema (MODS)|http://www.loc.gov/standards/mods/|Metadata Object Description Schema (MODS)] XML. The Dublin Core descriptive metadata is mapped to MODS since there is no official qualified Dublin Core XML schema in existence as of yet, and the Library Application Profile of DC that DSpace uses includes some qualifiers that are not part of the [DCMI Metadata Terms|http://dublincore.org/documents/dcmi-terms/|DCMI Metadata Terms].*  An _amdSec_ (administrative metadata section), which contains the a rights metadata element, which in turn contains the base64-encoded deposit license (the license the submitter granted as part of the submission process).*  A _fileSec_ containing a list of the bitstreams in the item. Each bundle constitutes a _fileGrp_. Each bitstream is represented by a _file_ element, which contains an _FLocat_ element with a simple XLink to the bitstream in the same directory as the _mets.xml_ file. The _file_ attributes consist of most of the basic technical metadata for the bitstream. Additionally, for those bitstreams that are thumbnails or text extracted from another bitstream in the item, those 'derived' bitstreams have the same _GROUPID_ as the bitstream they were derived from, in order that clients understand that there is a relationship.The _OWNERID_ of each _file_ is the 'persistent' bitstream identifier assigned by the DSpace instance. The _ID_ and _GROUPID_ attributes consist of the item's Handle, together with the bitstream's sequence ID, which underscores used in place of dots and slashes. For example, a bitstream with sequence ID 24, in the item _hdl:123.456/789_ will have the _ID__123_456_789_24_. This is because _ID_ and _GROUPID_ attributes must be of type _xsd:id_.h3. Limitations*  No corresponding import tool yet *  No _structmap_ section*  Some technical metadata not written, e.g. the primary bitstream in a bundle, original filenames or descriptions. *  Only the MIME type is stored, not the (finer grained) bitstream format. *  Dublin Core to MODS mapping is very simple, probably needs verification h2. MediaFilters: Transforming DSpace ContentDSpace can apply filters to content/bitstreams, creating new content. Filters are included that extract text for *full-text searching*, and create *thumbnails* for items that contain images. The media filters are controlled by the _MediaFilterManager_ which traverses the asset store, invoking the _MediaFilter_ or _FormatFilter_ classes on bitstreams. The media filter plugin configuration _filter.plugins_ in _dspace.cfg_ contains a list of all enabled media/format filter plugins (see Configuring Media Filters for more information). The media filter system is intended to be run from the command line (or regularly as a cron task):{code}[dspace]/bin/filter-media{code}With no options, this traverses the asset store, applying media filters to bitstreams, and skipping bitstreams that have already been filtered.*Available Command-Line Options:** *Help* : _\[dspace\]/bin/dspace filter-media -h_**  Display help message describing all command-line options. * *Force mode* : _\[dspace\]/bin/dspace filter-media -f_**  Apply filters to ALL bitstreams, even if they've already been filtered. If they've already been filtered, the previously filtered content is overwritten. * *Identifier mode* : _\[dspace\]/bin/dspace filter-media -i 123456789/2_**  Restrict processing to the community, collection, or item named by the identifier - by default, all bitstreams of all items in the repository are processed. The identifier must be a Handle, not a DB key. This option may be combined with any other option. * *Maximum mode* : _\[dspace\]/bin/dspace filter-media -m 1000_**  Suspend operation after the specified maximum number of items have been processed - by default, no limit exists. This option may be combined with any other option. * *No-Index mode* : _\[dspace\]/bin/dspace filter-media -n_**  Suppress index creation - by default, a new search index is created for full-text searching. This option suppresses index creation if you intend to run _index-update_ elsewhere.* *Plugin mode* : _\[dspace\]/bin/dspace filter-media -p "PDF Text Extractor","Word Text Extractor"_**  Apply ONLY the filter plugin(s) listed (separated by commas). By default all named filters listed in the _filter.plugins_ field of _dspace.cfg_ are applied. This option may be combined with any other option. _WARNING:_ multiple plugin names must be separated by a comma (i.e. ',') and NOT a comma followed by a space (i.e. ', ').* *Skip mode* : _\[dspace\]/bin/dspace filter-media -s 123456789/9,123456789/100_**  SKIP the listed identifiers (separated by commas) during processing. The identifiers must be Handles (not DB Keys). They may refer to items, collections or communities which should be skipped. This option may be combined with any other option. _WARNING:_ multiple identifiers must be separated by a comma (i.e. _','_) and NOT a comma followed by a space (i.e. _', '_).**  NOTE: If you have a large number of identifiers to skip, you may maintain this comma-separated list within a separate file (e.g. _filter-skiplist.txt_). Use the following format to call the program. _Please note the use of the "grave" or "tick" (_`_) symbol and do not use the single quotation. _*** _\[dspace\]/bin/dspace filter-media -s `less filter-skiplist.txt`_* *Verbose mode* : _\[dspace\]/bin/dspace filter-media -v_**  Verbose mode - print all extracted text and other filter details to STDOUT. Adding your own filters is done by creating a class which _implements_ the _org.dspace.app.mediafilter.FormatFilter_ interface. See the Creating a new Media Filter topic and comments in the source file FormatFilter.java for more information. In theory filters could be implemented in any programming language (C, Perl, etc.) However, they need to be invoked by the Java code in the Media Filter class that you create.h2. Sub-Community ManagementDSpace provides an administrative tool—'CommunityFiliator'—for managing community sub-structure. Normally this structure seldom changes, but prior to the 1.2 release sub-communities were not supported, so this tool could be used to place existing pre-1.2 communities into a hierarchy. It has two operations, either establishing a community to sub-community relationship, or dis-establishing an existing relationship.The familiar parent/child metaphor can be used to explain how it works. Every community in DSpace can be either a 'parent' community—meaning it has at least one sub-community, or a 'child' community—meaning it is a sub-community of another community, or both or neither. In these terms, an 'orphan' is a community that lacks a parent (although it can be a parent); 'orphans' are referred to as 'top-level' communities in the DSpace user-interface, since there is no parent community 'above' them. The first operation—establishing a parent/child relationship - can take place between any community and an orphan. The second operation - removing a parent/child relationship—will make the child an orphan.|Command used: |__\[dspace\]___/bin/dspace community-filiator_||Java class: |_org.dspace.administer.CommunityFiliator_||Arguments short and (long) forms: |Description ||_-s_ or _--set_|Set a parent/child relationship ||_-r_ or _--remove_|Remove a parent/child relationship ||_-c_ or _--child_|Child community (Handle or database ID) ||_-p_ or _--parent_|Parent community (Handle or database ID ||_-h_ or _--help_|Online help. |*Set* a parent/child relationship, issue the following at the CLI:_dsrun org.dspace.administer.CommunityFiliator --set --parent=parentID --child=childID_(or using the short form)_\[dspace\]/bin dspace community-filiator -s -p parentID -c childID_where '-s' or '--set' means establish a relationship whereby the community identified by the '-p' parameter becomes the parent of the community identified by the '-c' parameter. Both the 'parentID' and 'childID' values may be handles or database IDs.The reverse operation looks like this:_\[dspace\]/bin dspace community-filiator --remove --parent=parentID --child=childID_(or using the short form)_\[dspace\]/bin dspace community-filiator -r -p parentID -c childID_where '-r' or '--remove' means dis-establish the current relationship in which the community identified by 'parentID' is the parent of the community identified by 'childID'. The outcome will be that the 'childID' community will become an orphan, i.e. a top-level community.If the required constraints of operation are violated, an error message will appear explaining the problem, and no change will be made. An example in a removal operation, where the stated child community does not have the stated parent community as its parent: "Error, child community not a child of parent community".It is possible to effect arbitrary changes to the community hierarchy by chaining the basic operations together. For example, to move a child community from one parent to another, simply perform a 'remove' from its current parent (which will leave it an orphan), followed by a 'set' to its new parent.It is important to understand that when any operation is performed, all the sub-structure of the child community follows it. Thus, if a child has itself children (sub-communities), or collections, they will all move with it to its new 'location' in the community tree.h2. Batch Metadata EditingDSpace provides a batch metadata editing tool. The batch editing tool is able to produce a comma delimited file in the CVS format. The batch editing tool facilitates the user to perform the following:* Batch editing of metadata (e.g. perform an external spell check) * Batch additions of metadata (e.g. add an abstract to a set of items, add controlled vocabulary such as LCSH) * Batch find and replace of metadata values (e.g. correct misspelled surname across several records) * Mass move items between collections * Enable the batch addition of new items (without bitstreams) via a CSV file * Re-order the values in a list (e.g. authors) h3. Export FunctionThe following table summarizes the basics.|Command used: |__\[dspace\]___/bin/dspace metadata-export_||Java class: |org.dspace.app.bulkedit.MetadataExport ||Arguments short and (long) forms): |Description ||_-f_ or _--file_|Required. The filename of the resulting CSV. ||_-i_ or _--id_|The Item, Collection, or Community handle or Database ID to export. If not specified, *all* items will be exported.||_-a_ or _--all_|Include all the metadata fields that are not normally changed (e.g. provenance) or those fields you configured in the _dspace.cfg_ to be ignored on export.||_-h_ or _--help_|Display the help page. |h4. Exporting ProcessTo run the batch editing exporter, at the command line:_\[dspace\]/bin/dspace metadata-export -f name_of_file.csv -i 1023/24 _Example:_\[dspace\]/bin/dspace metadata-export -f /batch_export/col_14.csv -i /1989.1/24_In the above example we have requested that a collection, assigned handle '_1989.1/24_' export the entire collection to the file '_col_14.cvs_' found in the '_/batch_export_' directory.h3. Import FunctionThe following table summarizes the basics.|Command used: |__\[dspace\]___/bin/dspace metadata-import_||Java class: |org.dspace.app.bulkedit.MetadataImport ||Arguments short and (long) forms: |Description ||_-f_ or _--file_|Required. The filename of the CSV file to load. ||_-s_ or _--silent_|Silent mode. The import function does not prompt you to make sure you wish to make the changes. ||_-e_ or _--email_|The email address of the user. This is only required when adding new items. ||_-w_ or _--workflow_|When adding new items, the program will queue the items up to use the Collection Workflow processes. ||_-n_ or _--notify_|when adding new items using a workflow, send notification emails. ||_-t_ or _--template_|When adding new items, use the Collection template, if it exists. ||_-h_ or _--help_|Display the brief help page. |Silent Mode should be used carefully. It is possible (and probable) that you can overlay the wrong data and cause irreparable damage to the database. h4. Importing ProcessTo run the batch importer, at the command line:_\[dspace\]/bin/dspace metadata-import -f name_of_file.csv _Example_\[dspace\]/bin/dspace metadata-import -f /dImport/col_14.csv_If you are wishing to upload new metadata *without* bistreams, at the command line:_\[dspace\]/bin/dspace/metadata-import -f /dImport/new_file.csv -e joe@user.com -w -n -t_In the above example we threw in all the arguments. This would add the metadata and engage the workflow, notification, and templates to all be applied to the items that are being added.h3. The CSV FilesThe csv files that this tool can import and export abide by the RFC4180 CSV format [http://www.ietf.org/rfc/rfc4180.txt|http://www.ietf.org/rfc/rfc4180.txt|http://www.ietf.org/rfc/rfc4180.txt]. This means that new lines, and embedded commas can be included by wrapping elements in double quotes. Double quotes can be included by using two double quotes. The code does all this for you, and any good csv editor such as Excel or OpenOffice will comply with this convention.*File Structure.* The first row of the csv must define the metadata values that the rest of the csv represents. The first column must always be "id" which refers to the item'id. All other columns are optional. The other columns contain the dublin core metadata fields that the data is to reside. A typical heading row looks like:{code}id,collection,dc.title,dc.contributor,dc.date.issued,etc,etc,etc.{code}Subsequent rows in the csv file relate to items. A typical row might look like:{code}350,2292,Item title,"Smith, John",2008{code}If you want to store multiple values for a given metadata element, they can be separated with the double-pipe '||' (or another character that you defined in your _dspace.cfg _file. For example:{code}Horses||Dogs||Cats{code}Elements are stored in the database in the order that they appear in the csv file. You can use this to order elements where order may matter, such as authors, or controlled vocabulary such as Library of Congress Subject Headings.When importing a csv file, the importer will _overlay_ the data onto what is already in the repository to determine the differences. It only acts on the contents of the cvs file, rather than on the complete item metadata. This means that the CSV file that is exported can be manipulated quite substantially before being re-imported. Rows (items) or Columns (metadata elements) can be removed and will be ignored. For example, if you only want to edit item abstracts, you can remove all of the other columns and just leave the abstract column. (You do need to leave the ID column intact. This is mandatory).*Deleting Data.* It is possible to perform deletes across the board of certain metadata fields from an exported file. For example, let's say you have used keywords (dc.subject) that need to be removed _en masse_. You would leave the column (dc.subject) intact, but remove the data in the corresponding rows.*Migrating Data or Exchanging data.*It is possbile that you have data in one Dublin Core (DC) element and you wish to really have it in another. An example would be that your staff have input Library of Congress Subject Headings in the Subject field (dc.subject) instead of the LCSH field (dc.subject.lcsh). Follow these steps and your data is migrated upon import:# Insert a new column. The first row should be the new metadata element. (We will refer to it as the TARGET) # Select the column/rows of the data you wish to change. (We will refer to it as the SOURCE) # Cut and paste this data into the new column (TARGET) you created in Step 1. # Leave the column (SOURCE) you just cut and pasteed from empty. Do not delete it. h2. Checksum CheckerChecksum Checker is program that can run to verify the checksum of every item within DSpace. Checksum Checker was designed with the idea that most System Administrators will run it from the cron. Depending on the size of the repository choose the options wisely.|Command used: |__\[dspace\]___/bin/dspace checker_||Java class: |org.dspace.app.checker.ChecksumChecker ||Arguments short and (long) forms): |Description ||_-L_ or _--continuous_|Loop continuously through the bitstreams ||_-a_ or _--handle_|Specify a handle to check ||_-b_ <bitstream-ids>|Space separated list of bitstream IDs ||_-c_ or _--count_|Check count ||_-d_ or _--duration_|Checking duration ||_-h_ or _--help_|Calls online help ||_-l_ or _--looping_|Loop once through bitstreams ||_-p_ <prune>|Prune old results (optionally using specified properties file for configuration ||_-v_ or _--verbose_|Report all processing |There are three aspects of the Checksum Checker's operation that can be configured:* the execution mode * the logging output * the policy for removing old checksum results from the database The user should refer to Chapter 5. Configuration for specific configuration beys in the _dspace.cfg_ file.h3. Checker Execution ModeExecution mode can be configured using command line options. Information on the options are found in the previous table above. The different modes are described below.Unless a particular bitstream or handle is specified, the Checksum Checker will always check bitstreams in order of the least recently checked bitstream. (Note that this means that the most recently ingested bitstreams will be the last ones checked by the Checksum Checker.)*Available command line options** *Limited-count mode: *_\[dspace\]/bin/dspace checker -c_To check a specific number of bitstreams. The _-c_ option if followed by an integer, the number of bitstreams to check.Example: _\[dspace/bin/dspace checker -c 10_This is particularly useful for checking that the checker is executing properly. The Checksum Checker's default execution mode is to check a single bitstream, as if the option was _-c 1_* *Duration mode:*_\[dspace\]/bin/dspace checker -d_To run the Check for a specific period of time with a time argument. You may use any of the time arguments below:  Example: _\[dspace/bin/dspace checker -d 2h_ (Checker will run for 2 hours)|s |Seconds ||m |Minutes ||h |Hours ||d |Days ||w |Weeks ||y |Years |The checker will keep starting new bitstream checks for the specific durations, so actual execution duration will be slightly longer than the specified duration. Bear this in mind when scheduling checks. * *Specific Bistream mode:*_\[dspace\]/bin/dspace checker -b_Checker will only look at the internal bitsteam IDs. Example: _\[dspace\]/bin/dspace checker -b 112 113 4567_ Checker will only check bitstream IDs 112, 113 and 4567.* *Specific Handle mode:*_\[dspace\]/bin/dspace checker -a_Checkr will only check bistreams within the Community, Community or the item itself. Example: _\[dspace\]/bin/dspace checker -a 123456/999_ Checker will only check this handle. If it is a Collection or Community, it will run through the entire Collection or Community.The Check * *Looping mode:*_\[dspace\]/bin/dspace checker -l_ or _\[dspace\]/bin/dspace checker -L_There are two modes. The lowercase 'el' (-l) specifies to check every bitstream in the repository once. This is recommended for smaller repositories who are able to loop through all their content in just a few hours maximum. An uppercase 'L' (-L) specifies to continuously loops through the repository. This is not recommended for most repository systems.  *Cron Jobs*. For large repositories that cannot be completely checked in a couple of hours, we recommend the -d option in cron.* *Pruning mode:*_\[dspace\]/bin/dspace checker -p_The Checksum Checker will store the result of every check in the checksum_histroy table. By default, successful checksum matches that are eight weeks old or older will be deleted when the -p option is used. (Unsuccessful ones will be retained indefinitel). Without this option, the retention settings are ignored and the database table may grow rather large! h3. Checker Results PruningAs stated above in "Pruning mode", the checksum_history table can get rather large, and that running the checker with the -p assists in the size of the checksum_history being kept manageable. The amount of time for which results are retained in the checksum_history table can be modified by one of two methods: # Editing the retention policies in _\[dspace\]/config/dspace.cfg_ See Chapter 5 Configuration for the property keys.OR # Pass in a properties file containting retention policies when using the -p option. To do this, create a file with the following two property keys: {code}checker.retention.default = 10y
checker.retention.CHECKSUM_MATCH = 8w{code} You can use the table above for your time units.At the command line: {code}[dspace]/bin/dspace checker -p retention_file_name <ENTER>{code}h3. Checker ReportingChecksum Checker uses log4j to report its results. By default it will report to a log called _\[dspace\]/log/checker.log_, and it will report only on bitstreams for which the newly calculated checksum does not match the stored checksum. To report on all bitstreams checked regardless of outcome, use the _-v_ (verbose) command line option:_\[dspace\]/bin/dspace checker -l -v_ (This will loop through the repository once and report in detail about every bitstream checked.To change the location of the log, or to modify the prefix used on each line of output, edit the _\[dspace\]/config/templates/log4j.properties_ file and run _\[dspace\]/bin/install_configs_.h3. Cron or Automatic Execution of Checksum CheckerYou should schedule the Checksum Checker to run automatically, based on how frequently you backup your DSpace instance (and how long you keep those backups). The size of your repository is also a factor. For very large repositories, you may need to schedule it to run for an hour (e.g. _-d 1h_ option) each evening to ensure it makes it through your entire repository within a week or so. Smaller repositories can likely get by with just running it weekly.*Unix, Linux, or MAC OS*. You can schedule it by adding a cron entry similar to the following to the crontab for the user who installed DSpace:_0 4 ** 0 \[dspace\]/bin/dspace checker -d2h -p_The above cron entry would schedule the checker to run the checker every Sunday at 400 (4:00 a.m.) for 2 hours. It also specifies to 'prune' the database based on the retention settings in _dspace.cfg_.*Windows OS*. You will be unable to use the checker shell script. Instead, you should use Windows Schedule Tasks to schedule the following command to run at the appropriate times:_''\[dspace\]''/bin/dsrun.bat org.dspace.app.checker.ChecksumChecker -d2h -p_ (This command should appear on a single line).h3. Automated Checksum Checkers' ResultsOptionally, you may choose to receive automated emails listing the Checksum Checkers' results. Schedule it to run *after* the Checksum Checker has completed its processing (otherwise the email may not contain all the results).|Command used: |__\[dspace\]___/bin/dspace checker_||Java class: |org.dspace.checker.DailyReportEmailer ||Arguments short and (long) forms): |Description ||_-a_ or _--All_|Send all the results (everything specified below) ||_-d_ or _--Deleted_|Send E-mail report for all bitstreams set as deleted for today. ||_-m_ or _--Missing_|Send E-mail report for all bitstreams not found in assetstore for today. ||_-c_ or _--Changed_|Send E-mail report for all bitstrems where checksum has been changed for today. ||_-u_ or _--Unchanged_|Send the Unchecked bitstream report. ||_-n_ or _--Not Processed_|Send E-mail report for all bitstreams set to longer be processed for today. ||_-h_ or _--help_|Help |You can also combine options (e.g. -m -c) for combined reports.*Cron*. Follow the same steps above as you would running checker in cron. Change the time but match the regularity. Remember to schedule this **after** Checksum Checker has run.. EmbargoIf you have implemented the Embargo feature, you will need to run it periodically to check for Items with expired embargoes and lift them.|Command used: |__\[dspace\]___/bin/dspace embargo-lifter_||Java class: |org.dspace.embargo.EmbargoManager ||Arguments short and (long) forms): |Description ||_-c_ or _--check_|ONLY check the state of embargoed Items, do NOT lift any embargoes ||_-i_ or _--identifier_|Process ONLY this handle identifier(s), which must be an Item. Can be repeated. ||_-l_ or _--lift_|Only lift embargoes, do NOT check the state of any embargoed items. ||_-n_ or _--dryrun_|Do no change anything in the data model, print message instead. ||_-v_ or _--verbose_|Print a line describing the action taken for each embargoed item found. ||_-q_ or _--quiet_|No output except upon error. ||_-h_ or _--help_|Display brief help screen. |You must run the Embargo Lifter task periodically to check for items with expired embargoes and lift them from being embargoed. For example, to check the status, at the CLI:_\[dspace\]/bin/dspace embargo-lifter -c_To lift the actual embargoes on those items that meet the time criteria, at the CLI:_\[dspace\]/bin/dspace embargo-lifter -l_. Browse Index CreationTo create all the various browse indexes that you define in the Configuration Section (Chapter 5) there are a variety of options available to you. You can see these options below in the command table.|Command used: |__\[dspace\]___/bin/dspace index-init_||Java class: |org.dspace.browse.IndexBrowse ||Arguments short and long forms): |Description ||_-r_ or _--rebuild_|Should we rebuild all the indexes, which removes old tables and creates new ones. For use with _-f_. Mutually exclusive with _-d_||_-s_ or _--start_|_\[-s <int>\] _start from this index number and work upwards (mostly only useful for debugging). For use with _-t_ and _-f_||_-x_ or _--execute_|Execute all the remove and create SQL against the database. For use with _-t _and _-f_||_-i_ or _--index_|Actually do the indexing. Mutually exclusive with _-t_ and _-f_.||_-o_ or _--out_|_\[-o<filename>\]_ write the remove and create SQL to the given file. For use with _-t_ and _-f_||_-p_ or _--print_|Write the remove and create SQL to the stdout. For use with _-t_ and _-f_.||_-t_ or _--tables_|Create the tables only, do no attempt to index. Mutually exclusive with _-f_ and _-i_||_-f_ or _--full_|Make the tables, and do the indexing. This forces _-x_. Mutually exclusive with _-f_ and _-i_.||_-v_ or _--verbose_|Print extra information to the stdout. If used in conjunction with _-p_, you cannot use the stdout to generate your database structure.||_-d_ or _--delete_|Delete all the indexes, but do not create new ones. For use with _-f_. This is mutually exclusive with _-r_.||_-h_ or _--help_|Show this help documentation. Overrides all other arguments. |. Running the Indexing Programs*Complete Index Regeneration*. By running _\[dspace\]/bin/dspace index-init_ you will completely regenerate your indexes, tearing down all old tables and reconstructing with the new cofiguration. Running this is the same as:_\[dspace\]/bin/dsrun org.dspace.browse.IndexBrowse -f -r_*Updating the Indexes*. By running _dspace/bin/dspace index-update_ you will reindex your full browse wihtout modifying the table structure. (This should be your default approach if indexing, for example, via a cron job periodically). Running this is the same as:_\[dspace\]/bin/dsrun org.dspace.browse.IndexBrowse -i_*Destroy and rebuild.* You can destroy and rebuild the database, but do not do the indexing. Output the SQL to do this to the screen and a file, as well as executing it against the database, while being verbose. At the CLI screen:_\[dspace\]/bin/dsrun org.dspace.browse.IndexBrowse -r -t -p -v -x -o myfile.sql_. Indexing CustomizationDSpace provides robust browse indexing. It is possible to expand upon the default indexes delivered at the time of the installation. The System Administrator should review "Defining the Indexes" from the Chapter 5. Configuration to become familiar with the property keys and the definitions used therein before attempting heavy customizations.Through customization is is possible to:* Add new browse indexes besides the four that are delivered upon installation. Examples: ** Series ** Specific subject fields (Library of Congress Subject Headings._(It is possible to create a browse index based on a controlled vocabulary or thesauris.)_** Other metadata schema fields * Combine metadata fields into one browse * Combine different metadata schemas in one browse *Examples of new browse indexes that are possible.*_(The system administrator is reminded to read the section on Defining the Indexes in Chapter 5. Configuration.)_* *Add a Series Browse*. You want to add a new browse using a previously unused metadata element. _webui.browse.index.6 = series:metadata:dc.relation.ispartofseries:text:single_Note: the index # need to be adjusted to your browse stanza in the _dspace.cfg_ file. Also, you will need to update your _Messages.properties_ file. * *Combine more than one metadata field into a browse.* You may have other title fields used in your repository. You may only want one or two of them added, not all title fields. And/or you may want your series to file in there. _webui.browse.index.3 = title:metadata:dc.title,dc:title.uniform,dc:relation.ispartofseries:title:full_* *Separate subject browse.* You may want to have a separate subject browse limited to only one type of subject. _webui.browse.index.7 = lcsubject.metdata:dc.subject.lcsh.text:single_As one can see, the choices are limited only by your metadata schema, the metadata, and your imagination.Remember to run _index-init_ after adding any new defitions in the _dspace.cfg_ to have the indexes created and the data indexed.