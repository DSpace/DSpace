## File for changes to dspace.cfg - separated from original configuration file to see what we changed
# one day similar to this
# https://github.com/ufal/clarin-dspace/blob/clarin/utilities/project_helpers/config/local.conf.dist

#------------------------------------------------------------------#
#---------------------------DSpace---------------------------------#
#------------------------------------------------------------------#
dspace.name.short = DSpace
dspace.name = CLARIN DSpace

#------------------------------------------------------------------#
#---------------------------UPLOAD FILE----------------------------#
#------------------------------------------------------------------#

# Maximum size of a single uploaded file
# The file bigger than maximum upload size could be uploaded by adding file URL to the
# `local.bitstream.redirecToURL` metadata in the submission UI process.
spring.servlet.multipart.max-file-size = 4GB

# Maximum size of a multipart request (i.e. max total size of all files in one request)
spring.servlet.multipart.max-request-size = 4GB

#------------------------------------------------------------------#
#---------------------------PID CONFIG-----------------------------#
#------------------------------------------------------------------#

# PID service
# type o service; for now only epic and epic2 are supported
lr.pid.service.type = epic2
lr.pid.service.url = https://handle.gwdg.de/pidservice/
lr.pid.service.user =
lr.pid.service.pass =

# per community pid configurations for pid prefixes of the format:
# community=<community ID>,prefix=<prefix>,alternative_prefixes=<pipeline separated list of alternative prefixes>,type=<local|epic>,canonical_prefix=<URL of handle>,subprefix=<subprefix>
# community=<community ID> is required
# multiple configurations can be added using a new configuration line
# default configuration should have asterisk as the community ID
# subprefix is only used for local handles
lr.pid.community.configurations = community=47501cdc-e2eb-44e5-85e0-89a31dc8ceee, prefix=123456789, type=local, canonical_prefix=http://hdl.handle.net/, subprefix=1
lr.pid.community.configurations = community=09f09b11-cba1-4c43-9e01-29fe919991ab, prefix=123456789, type=local, canonical_prefix=http://hdl.handle.net/, subprefix=2
lr.pid.community.configurations = community=*, prefix=123456789, type=local, canonical_prefix=http://hdl.handle.net/, subprefix=2
# if true, PID metadata will be filled with object metadata like title
lr.pid.resolvemetadata = true

######
#
# Shortener
#
#####
# shortener.enabled = ${lr.shortener.enabled}
shortener.handle.prefix = 1234
# separate the patterns with ; that is less likely to appear as pattern char
shortener.post.url.blacklist.regexps = .*://.\{1,15\}
shortener.post.host.whitelist.regexps = (.*\\.)?google\\.com
shortener.post.host.blacklist.regexps = .*\\.com;.*\\.xyz;.*\\.ga;.*\\.br;.*\\.app
shortener.post.error = Data POSTed by you didn't pass the validation. Please check that you've supplied the title, \
the email and the url is not on *.com domain and the part after schema:// is longer than 15 chars

##### HELP DESK #####
# `lr.help.mail` is exposed to the FE - must be set as exposed

lr.help.mail = test@test.sk
lr.help.phone = 0000

# Admin could upload the file bigger than maximum upload size.
# Should be this big file deleted from the '/temp' folder?
delete.big.file.after.upload = true


##### BITSTREAM DOWNLOAD #####
bitstream.download.token.expiration.days = 15

##### VALIDATION #####
# Whether or not we REQUIRE that a distribution license must be accepted
# during the 'ClarinLicenseDistribution' step in the submission process
# Defaults to true; If set to 'false'
webui.submit.distribution.license.required = true

### Add user to the groups ###
#attribute -> group mapping
#check shibboleth attribute ATTR and put users having value ATTR_VALUE1 and ATTR_VALUE2 to GROUP1
#users having ATTR_VALUE3 to GROUP2
#groups must exist
#authentication-shibboleth.header.ATTR=ATTR_VALUE1=>GROUP1,ATTR_VALUE2=>GROUP1,ATTR_VALUE3=>GROUP2
#examples:
authentication-shibboleth.header.entitlement = staff@org1297.mff.cuni.cz => UFAL_MEMBER,urn:cuni:affiliation:staff@mff.cuni.cz => CUNI_STAFF,urn:mace:eduid.cz:affiliation:interrupted-student => INTERRUPTED_STUDENTS
authentication-shibboleth.header.unscoped-affiliation = member => MEMBERS, staff=> STAFF, employee => EMPLOYEES, alum => ALUMS

# The shibboleth header to do role-based mappings
# UFAL: To automatically choose role you have to specify attribute which is looking at
#       see ShibGroup.java
authentication-shibboleth.role-header = entitlement

# Whether to ignore the attribute's scope or value.
# scope is the part after @
authentication-shibboleth.role-header.ignore-scope = false
authentication-shibboleth.role-header.ignore-value = true

##### CLARIN Shibboleth Settings ######

# Group for all who log through shibboleth, the group must exist in dspace
authentication-shibboleth.default.auth.group = Authenticated

# Default group for UFAL members
# - if "ufal.mff.cuni.cz" matches the scoped organisation header,
#   the user will get automatically into UFAL group
authentication-shibboleth.role.ufal.mff.cuni.cz = UFAL

# Possible Authorizations for the user. If the user is added to the group, the authorization must be added too.
# Authorization is assigned to the user in the `EPersonRestAuthenticationProvider` class.
authentication-shibboleth.clarin.custom.groups = UFAL,UFAL_MEMBER

# Show attributes which are passed by IdP on the first login
# Default - false
authentication-shibboleth.show.idp-attributes = false


###############
#
# featured services config
#
###############
featured.services = pmltq,kontext,teitok
featured.service.kontext.fullname = KonText
featured.service.kontext.url = http://lindat.mff.cuni.cz/services/kontext
featured.service.kontext.description = KonText is a basic web application for querying corpora
featured.service.pmltq.fullname = PML-TQ
featured.service.pmltq.url = https://lindat.mff.cuni.cz/services/pmltq/
featured.service.pmltq.description = Tool for searching and browsing treebanks online
featured.service.teitok.fullname = TEITOK
featured.service.teitok.url = https://lindat.mff.cuni.cz/services/teitok/
featured.service.teitok.description = A web-based platform for viewing, creating, and editing corpora


##### Shibboleth #####
# Turn off the discofeed, it is allowed by default
shibboleth.discofeed.allowed = false
# File where is DiscoJuiceFeed response
shibboleth.discofeed.url = https://dev-5.pc:8443/Shibboleth.sso/DiscoFeed

# CRON job refresh time definition - default is refresh in every 2 hours.
discojuice.refresh = 0 0 */2 * * ?
# Comma separated list of entityIDs; we try to guess country on these
discojuice.rewriteCountries = https://idp.scc.kit.edu/idp/shibboleth, https://fedauth.london.edu/oala/metadata, https://youidlite.youid.net/idp/shibboleth, https://cavle.org/shibboleth

# Disable SSL check for specific requests e.g. discofeed. SSL check is enabled by default.
disable.ssl.check.specific.requests = false

##### Matomo statistics #####
# Auth token
matomo.track.enabled = true
matomo.auth.token = 26388b4164695d69e6ee6e2dd527b723
matomo.site.id = 1
matomo.tracker.bitstream.site_id = 1
matomo.tracker.oai.site_id = 1
statistics.cache-server.uri = http://cache-server.none

#### Statistic usage reports ####
# site.usage-reports.enable.auth.anonymous = true


##### Citacepro config #####
# citace.pro.url = https://www.citacepro.com/api/dspace/citace/oai
# citace.pro.university = dspace.tul.cz

# only use true or false for the value of citace pro allowed
# citace.pro.allowed = true

#google config
# google.analytics.key =

# The max number of events held in the GA buffer (default: 256)
# google.analytics.buffer.limit = 256

# Define cron for how frequently events tracked in the DSpace backend will be sent to Google Analytics
# This MUST be enabled if you wish to use `google.analytics.api-secret` to track bitstream download statistics (and similar)
# Cron syntax is defined at https://www.quartz-scheduler.org/api/2.3.0/org/quartz/CronTrigger.html
# Keep in mind, changing the schedule requires rebooting your servlet container, e.g. Tomcat.
# The below example will run this task daily, every 5 minutes
# google.analytics.cron = 0 0/1 * * * ?

# Defines a Measurement Protocol API Secret to be used to track interactions which occur outside of the user's browser.
# For example , this is required to track downloads of bitstreams. This setting is only used by Google Analytics 4.
# For more details see https://developers.google.com/analytics/devguides/collection/protocol/ga4
# google.analytics.api-secret =

##### Importing #####
import.metadata.field.not.update = dc.description.provenance, dc.date.available, dc.date.accessioned, dc.identifier.uri

#------------------------------------------------------------------#
#-------------------------Configure DOI----------------------------#
#------------------------------------------------------------------#

# Credentials used to authenticate against the registration agency:
identifier.doi.user = username
identifier.doi.password = password
# DOI prefix used to mint DOIs. All DOIs minted by DSpace will use this prefix.
# The Prefix will be assigned by the registration agency.
identifier.doi.prefix = 10.5072
# If you want to, you can further separate your namespace. Should all the
# suffixes of all DOIs minted by DSpace start with a special string to separate
# it from other services also minting DOIs under your prefix?
identifier.doi.namespaceseparator = dspace/

##
## Configure XSLT-driven submission crosswalk for DataCite
##
crosswalk.dissemination.DataCite.stylesheet = crosswalks/DIM2DataCite.xsl
crosswalk.dissemination.DataCite.schemaLocation = \
    http://datacite.org/schema/kernel-3 \
    http://schema.datacite.org/meta/kernel-3/metadata.xsd
crosswalk.dissemination.DataCite.preferList = false
crosswalk.dissemination.DataCite.publisher = My University
#crosswalk.dissemination.DataCite.dataManager = # defaults to publisher
#crosswalk.dissemination.DataCite.hostingInstitution = # defaults to publisher
crosswalk.dissemination.DataCite.namespace = http://datacite.org/schema/kernel-3

# consumer to update metadata of DOIs
event.consumer.doi.class = org.dspace.identifier.doi.DOIConsumer
event.consumer.doi.filters = Item+Modify_Metadata

# Add doi here if you are using org.dspace.identifier.DOIIdentifierProvider to generate DOIs.
# Adding doi here makes DSpace send metadata updates to your doi registration agency.
# Add rdf here, if you are using dspace-rdf to export your repository content as RDF.
# Add iiif here, if you are using dspace-iiif.
event.dispatcher.default.consumers = versioning, discovery, eperson

# Edit Item - Status option
identifiers.item-status.register-doi = false

##### Dataquest URL - sing in the footer #####
themed.by.url = https://www.dataquest.sk/dspace
themed.by.company.name = dataquest s.r.o.


#### Authority configuration `authority.cfg`
## dc.relation authority is configured only because of correct item importing, but it is not used anymore.
authority.controlled.dc.relation = true

#nameConversion
shibboleth.name.conversion.inputEncoding = ISO-8859-1
shibboleth.name.conversion.outputEncoding = UTF-8

### File preview ###
# File preview is enabled by default
file.preview.enabled = false

### Storage service ###
# Synchronization is NOT enabled by default
sync.storage.service.enabled = true
# Upload large file by parts - check the checksum of every part
s3.upload.by.parts.enabled = true


### The build version is stored in the specific file ###
build.version.file.path = ${dspace.dir}/config/VERSION_D.txt


#### Item View ####
# Show handle and doi as identifiers - show only DOI if it exists instead of handle by default
item-page.show-handle-and-doi = false